# TreeDRNet: Forecasting de Series de Tiempo en el Dataset ETT

Este proyecto implementa el modelo **TreeDRNet** (Tree-based Deep Residual Network) para la predicciÃ³n de series de tiempo a largo plazo utilizando el dataset ETT (Electricity Transformer Temperature).

## ğŸ“‹ DescripciÃ³n del Proyecto

El objetivo principal es aplicar el approach propuesto en el paper **"TreeDRNet: A Robust Deep Model for Long Term Time Series Forecasting"** para predecir la temperatura del aceite (OT - Oil Temperature) en transformadores elÃ©ctricos a travÃ©s de mÃºltiples horizontes temporales.

### Dataset

Utilizamos el **ETDataset** de [zhouhaoyi/ETDataset](https://github.com/zhouhaoyi/ETDataset), que contiene datos de transformadores elÃ©ctricos registrados entre 2016/07 y 2018/07. El dataset incluye las siguientes variables:

- **HUFL**: High UseFul Load
- **HULL**: High UseLess Load  
- **MUFL**: Middle UseFul Load
- **MULL**: Middle UseLess Load
- **LUFL**: Low UseFul Load
- **LULL**: Low UseLess Load
- **OT**: Oil Temperature (variable objetivo)

Trabajamos con cuatro variantes del dataset:
- `ETTh1`: Transformador 1, muestreo horario
- `ETTh2`: Transformador 2, muestreo horario
- `ETTm1`: Transformador 1, muestreo por minuto
- `ETTm2`: Transformador 2, muestreo por minuto

## ğŸ¯ ConfiguraciÃ³n Experimental

### Ventanas de Tiempo
- **Longitud de entrada (L)**: 96 pasos temporales
- **Horizontes de predicciÃ³n (H)**: {24, 48, 96, 192, 336, 720} pasos

### Split Temporal
Los datos se dividen de forma temporal (sin shuffle) en:
- **Train**: 70% de los datos
- **ValidaciÃ³n**: 10% de los datos  
- **Test**: 20% de los datos

### MÃ©tricas de EvaluaciÃ³n
Para cada horizonte se reportan las siguientes mÃ©tricas en el conjunto de test:
- **MSE** (Mean Squared Error)
- **MAE** (Mean Absolute Error)
- **RMSE** (Root Mean Squared Error)
- **MAPE** (Mean Absolute Percentage Error)
- **RÂ²** (Coeficiente de determinaciÃ³n)

## ğŸ—ï¸ Arquitectura del Modelo

El modelo TreeDRNet implementado incluye:

- **Estructura jerÃ¡rquica tipo Ã¡rbol** con residuales profundos
- **MÃºltiples ramas paralelas** con mecanismos de gating
- **Convoluciones 1x1** para procesamiento de covariables temporales
- **Backcast y forecast** en cada bloque residual
- **Dropout regularization** para prevenir overfitting

### HiperparÃ¡metros Principales
```python
EPOCAS = 60
BATCH = 32
LR = 1e-4
SEED = 42

TD_OCULTO = 128        # Hidden dimension
TD_PROF = 3            # Tree depth
TD_RAMAS = 2           # Number of branches
```

### TÃ©cnicas de OptimizaciÃ³n
- **Optimizer**: AdamW con weight decay = 1e-2
- **Learning Rate Scheduler**: ReduceLROnPlateau
- **Early Stopping**: Paciencia de 8 Ã©pocas
- **Gradient Clipping**: max_norm = 1.0
- **Mixed Precision Training**: AMP con bfloat16

## ğŸ“ Estructura del Proyecto

```
Lab2/
â”œâ”€â”€ datos/
â”‚   â””â”€â”€ ETT-small/
â”‚       â”œâ”€â”€ ETTh1.csv
â”‚       â”œâ”€â”€ ETTh2.csv
â”‚       â”œâ”€â”€ ETTm1.csv
â”‚       â””â”€â”€ ETTm2.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ modelos/
â”‚   â”‚   â””â”€â”€ treedrnet.py          # ImplementaciÃ³n del modelo TreeDRNet
â”‚   â”œâ”€â”€ preprocesamiento.py       # Carga y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ entrenamiento.py          # Loop de entrenamiento y evaluaciÃ³n
â”‚   â”œâ”€â”€ graficas.py               # VisualizaciÃ³n de resultados
â”‚   â””â”€â”€ utils.py                  # Utilidades generales
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ metricas/                 # MÃ©tricas consolidadas
â”‚   â””â”€â”€ <DATASET>/                # Por cada dataset
â”‚       â”œâ”€â”€ H<horizonte>/
â”‚       â”‚   â”œâ”€â”€ pesos/            # Checkpoints del modelo
â”‚       â”‚   â”œâ”€â”€ metricas/         # CSV con historial de entrenamiento
â”‚       â”‚   â””â”€â”€ graficas/         # GrÃ¡ficas de mÃ©tricas y predicciones
â”‚       â”œâ”€â”€ metricas/             # Resultados por dataset
â”‚       â””â”€â”€ graficas/             # Comparativas por horizonte
â”œâ”€â”€ experimentos.py               # Script principal de ejecuciÃ³n
â””â”€â”€ README.md
```

## ğŸš€ Uso

### Requisitos

```bash
pip install torch numpy pandas scikit-learn matplotlib
```

### EjecuciÃ³n

Para ejecutar todos los experimentos (4 datasets Ã— 6 horizontes):

```bash
python experimentos.py
```

El script automÃ¡ticamente:
1. Carga cada dataset (ETTh1, ETTh2, ETTm1, ETTm2)
2. Para cada horizonte {24, 48, 96, 192, 336, 720}:
   - Crea ventanas deslizantes de longitud 96
   - Entrena el modelo TreeDRNet
   - Guarda el mejor checkpoint segÃºn MSE en validaciÃ³n
   - EvalÃºa en el conjunto de test
   - Genera grÃ¡ficas de mÃ©tricas y predicciones
3. Consolida resultados globales en CSV

### Resultados

Los resultados se guardan automÃ¡ticamente en:

- **Pesos del modelo**: `resultados/<DATASET>/H<H>/pesos/`
- **MÃ©tricas de entrenamiento**: `resultados/<DATASET>/H<H>/metricas/`
- **GrÃ¡ficas individuales**: `resultados/<DATASET>/H<H>/graficas/`
- **MÃ©tricas consolidadas**: `resultados/metricas/TEST_resultados.csv`

## ğŸ“Š Visualizaciones

El proyecto genera automÃ¡ticamente las siguientes grÃ¡ficas:

### Por Experimento (dataset + horizonte)
- EvoluciÃ³n de MSE, MAE, RMSE, MAPE, RÂ² durante entrenamiento
- Learning rate por Ã©poca
- Velocidad de entrenamiento (iteraciones/s, muestras/s)
- Serie temporal de la Ãºltima ventana de test (predicciÃ³n vs real)

### Por Dataset
- Comparativa de mÃ©tricas vs horizonte de predicciÃ³n

## ğŸ”¬ Detalles de ImplementaciÃ³n

### Preprocesamiento
- NormalizaciÃ³n usando `StandardScaler` (ajustado solo en train)
- Ventanas deslizantes sin solapamiento entre splits
- PredicciÃ³n univariada (OT) con covariables multivariadas

### Entrenamiento
- Dataset loader con pin_memory y persistent_workers para eficiencia
- Checkpoint basado en mejor MSE de validaciÃ³n
- Soporte para CUDA con mixed precision training

### EvaluaciÃ³n
- MAPE calculado en escala original (desnormalizado)
- MÃ©tricas promediadas sobre todas las ventanas de test

## ğŸ“– Referencias

### Paper Implementado

**TreeDRNet: A Robust Deep Model for Long Term Time Series Forecasting**

Zhou, T., Zhu, J., Wang, X., Ma, Z., Wen, Q., Sun, L., & Jin, R. (2022). TreeDRNet: A Robust Deep Model for Long Term Time Series Forecasting. arXiv preprint arXiv:2206.12106.

**Paper**: [https://arxiv.org/abs/2206.12106](https://arxiv.org/abs/2206.12106)

```bibtex
@article{zhou2022treedrnet,
  title={TreeDRNet: A Robust Deep Model for Long Term Time Series Forecasting},
  author={Zhou, Tian and Zhu, Jianqing and Wang, Xue and Ma, Ziqing and Wen, Qingsong and Sun, Liang and Jin, Rong},
  journal={arXiv preprint arXiv:2206.12106},
  year={2022}
}
```

**CaracterÃ­sticas clave del paper**:
- Doubly Residual (DRes) link structure para predicciones mÃ¡s robustas
- Estructura de Ã¡rbol para ensemble de modelos
- Mecanismo de gating para selecciÃ³n de features
- Basado completamente en MLPs (10x mÃ¡s eficiente que Transformers)
- Reduce errores de predicciÃ³n en 20-40% comparado con SOTA

### Dataset

Zhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., & Zhang, W. (2021). Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting. AAAI Conference on Artificial Intelligence, 35(12), 11106-11115.

**Dataset Repository**: [https://github.com/zhouhaoyi/ETDataset](https://github.com/zhouhaoyi/ETDataset)

```bibtex
@inproceedings{haoyietal-informer-2021,
  author    = {Haoyi Zhou and Shanghang Zhang and Jieqi Peng and 
               Shuai Zhang and Jianxin Li and Hui Xiong and Wancai Zhang},
  title     = {Informer: Beyond Efficient Transformer for Long Sequence 
               Time-Series Forecasting},
  booktitle = {The Thirty-Fifth {AAAI} Conference on Artificial Intelligence},
  volume    = {35},
  number    = {12},
  pages     = {11106--11115},
  publisher = {{AAAI} Press},
  year      = {2021},
}
```

## ğŸ“ Notas

- El proyecto sigue principios de clean code sin comentarios
- La arquitectura utiliza clean architecture patterns
- Los tests siguen un approach basado en tablas de casos
- Seed fijada (42) para reproducibilidad

## ğŸ”§ PersonalizaciÃ³n

Para modificar los experimentos, edita los parÃ¡metros en `experimentos.py`:

```python
DATASETS = ["ETTh1", "ETTh2", "ETTm1", "ETTm2"]
HORIZONTES = [24, 48, 96, 192, 336, 720]
LONG_VENTANA = 96

EPOCAS = 60
BATCH = 32
LR = 1e-4

TD_OCULTO = 128
TD_PROF = 3
TD_RAMAS = 2
```

